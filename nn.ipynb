{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2c9aee-d95f-4b9e-abbf-2cadab2ee821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "import keras_tuner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import integrate\n",
    "import tf_keras as keras\n",
    "\n",
    "from models.nn import build_model\n",
    "from har import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045bb792-cd07-4082-a070-5d876a776560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_qscore(conditional_dist):\n",
    "    d = conditional_dist\n",
    "    def qscore(a, y):\n",
    "        q = d.quantile(a).numpy().flatten()[0]\n",
    "        return ((y <= q) - a) * (q - y)\n",
    "    return qscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87b5ec-06d9-4fb9-9b0d-b7f4202aaecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bound = 4600\n",
    "val_bound = 4600 // 10 * 8\n",
    "\n",
    "results = []\n",
    "best_hp = defaultdict(dict)\n",
    "\n",
    "for csv_path in Path('data/TAQ').iterdir():\n",
    "    company = csv_path.stem.split('_')[0]\n",
    "    data = get_data(csv_path)\n",
    "    x_train, y_train = data[:val_bound, 1:], data[:val_bound, 0]\n",
    "    x_val, y_val = data[val_bound: test_bound, 1:], data[val_bound: test_bound, 0]\n",
    "    x_test, y_test = data[test_bound:, 1:], data[test_bound:, 0]\n",
    "    for dist in distributions:\n",
    "        hypermodel = partial(build_model, dist_name=dist)\n",
    "        tuner = keras_tuner.RandomSearch(\n",
    "            hypermodel=hypermodel,\n",
    "            objective=keras_tuner.Objective(\"val_loss\", \"min\"),\n",
    "            max_trials=10,\n",
    "            overwrite=True,\n",
    "            directory=f\"./trials\",\n",
    "        )\n",
    "        tuner.search(\n",
    "          x_train, y_train,\n",
    "          validation_data=(x_val, y_val),\n",
    "          epochs=30,\n",
    "          callbacks=[early_stop]\n",
    "        )\n",
    "        best_model = tuner.get_best_models()[0]\n",
    "        l_score = best_model.evaluate(x_test, y_test)\n",
    "        crps = []\n",
    "        for i in range(len(x_test)):\n",
    "            y_hat = best_model(x_test[i].reshape(1,3))\n",
    "            crps_res = tanhsinh(\n",
    "              make_qscore(y_hat), \n",
    "              np.zeros(1), \n",
    "              np.ones(1), \n",
    "              args=(y_test[i])\n",
    "            )\n",
    "            crps.append(crps_res.integral)\n",
    "\n",
    "        results.append([company, dist, l_score, np.mean(crps)])\n",
    "        best_hp[company][dist] = tuner.get_best_hyperparameters()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812310b8-9e99-488f-8b8a-b546f8636816",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results, cols=['company', 'distribution', 'l_score', 'crps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cb220f-fb5e-452b-be28-fc18e67dd293",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('nn_results.csv')\n",
    "with open('nn_model_hp.json', 'w') as jfile:\n",
    "    json.dump(best_hp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
